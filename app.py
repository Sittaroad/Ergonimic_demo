import streamlit as st
import cv2
import numpy as np
from PIL import Image
from ultralytics import YOLO
import mediapipe as mp
import os
import time

# -----------------------
# ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏´‡∏ô‡πâ‡∏≤‡πÄ‡∏ß‡πá‡∏ö
# -----------------------
st.set_page_config(
    page_title="Ergonomic",
    page_icon="ü™ë",
    layout="centered"
)

st.title("Ergonomic")
st.caption("‡πÉ‡∏ä‡πâ YOLO + Pose ‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏°‡∏∏‡∏°‡∏Ñ‡∏≠ ‡∏´‡∏•‡∏±‡∏á ‡πÄ‡∏Ç‡πà‡∏≤ ‡∏à‡∏≤‡∏Å‡∏†‡∏≤‡∏û‡∏î‡πâ‡∏≤‡∏ô‡∏Ç‡πâ‡∏≤‡∏á")

# ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏• YOLO (cache)
@st.cache_resource
def load_yolo_model():
    model_path = "best.pt"
    if not os.path.exists(model_path):
        st.error(f"‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå‡πÇ‡∏°‡πÄ‡∏î‡∏• {model_path} ‡πÉ‡∏ô‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô")
        st.stop()
    model = YOLO(model_path)
    return model

yolo_model = load_yolo_model()

#MediaPipe Pose
mp_pose = mp.solutions.pose
mp_drawing = mp.solutions.drawing_utils

pose = mp_pose.Pose(
    static_image_mode=False,
    model_complexity=1,
    enable_segmentation=False,
    min_detection_confidence=0.5,
    min_tracking_confidence=0.5
)

# ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏ä‡πà‡∏ß‡∏¢‡∏î‡πâ‡∏≤‡∏ô‡∏¢‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå
def calculate_angle(a, b, c):
    a = np.array(a)
    b = np.array(b)
    c = np.array(c)

    ba = a - b
    bc = c - b

    norm_ba = np.linalg.norm(ba)
    norm_bc = np.linalg.norm(bc)
    if norm_ba < 1e-6 or norm_bc < 1e-6:
        return None

    cos_ang = np.dot(ba, bc) / (norm_ba * norm_bc)
    cos_ang = np.clip(cos_ang, -1.0, 1.0)
    angle = np.degrees(np.arccos(cos_ang))
    return angle

def flex_from_straight(angle):
    if angle is None:
        return None
    return abs(180.0 - angle)

def choose_side_landmarks(landmarks):
    lm = mp_pose.PoseLandmark

    def get_xyz(id_):
        p = landmarks[id_]
        return p.x, p.y, p.visibility

    left_ids = [lm.LEFT_EAR, lm.LEFT_SHOULDER, lm.LEFT_HIP, lm.LEFT_KNEE, lm.LEFT_ANKLE]
    right_ids = [lm.RIGHT_EAR, lm.RIGHT_SHOULDER, lm.RIGHT_HIP, lm.RIGHT_KNEE, lm.RIGHT_ANKLE]

    left_points = [get_xyz(int(i.value)) for i in left_ids]
    right_points = [get_xyz(int(i.value)) for i in right_ids]

    left_vis = np.mean([p[2] for p in left_points])
    right_vis = np.mean([p[2] for p in right_points])

    if left_vis >= right_vis:
        side = "left"
        ear = left_points[0][:2]
        shoulder = left_points[1][:2]
        hip = left_points[2][:2]
        knee = left_points[3][:2]
        ankle = left_points[4][:2]
    else:
        side = "right"
        ear = right_points[0][:2]
        shoulder = right_points[1][:2]
        hip = right_points[2][:2]
        knee = right_points[3][:2]
        ankle = right_points[4][:2]

    return side, {
        "ear": ear,
        "shoulder": shoulder,
        "hip": hip,
        "knee": knee,
        "ankle": ankle,
    }

def classify_ergonomic(neck_flex, trunk_flex, knee_angle):
    if neck_flex is None or trunk_flex is None or knee_angle is None:
        return "‡πÑ‡∏°‡πà‡πÅ‡∏ô‡πà‡πÉ‡∏à", "unknown", ["‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏à‡∏∏‡∏î‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡πÑ‡∏°‡πà‡∏Ñ‡∏£‡∏ö (neck/trunk/knee ‡πÄ‡∏õ‡πá‡∏ô None)"]

    reason = []

    # ‡∏Ñ‡∏≠
    if neck_flex <= 20:
        reason.append(f"‡∏Ñ‡∏≠‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏ä‡πà‡∏ß‡∏á‡∏î‡∏µ (‡πÄ‡∏ö‡∏µ‡πà‡∏¢‡∏á‡∏à‡∏≤‡∏Å‡πÅ‡∏ô‡∏ß‡∏ï‡∏£‡∏á ~ {neck_flex:.1f}¬∞)")
        neck_score = 2
    elif neck_flex <= 45:
        reason.append(f"‡∏Ñ‡∏≠‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏Å‡πâ‡∏°/‡πÄ‡∏á‡∏¢‡∏°‡∏≤‡∏Å (~ {neck_flex:.1f}¬∞)")
        neck_score = 1
    else:
        reason.append(f"‡∏Ñ‡∏≠‡∏Å‡πâ‡∏°/‡πÄ‡∏á‡∏¢‡∏°‡∏≤‡∏Å‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ (~ {neck_flex:.1f}¬∞)")
        neck_score = 0

    # ‡∏´‡∏•‡∏±‡∏á
    if trunk_flex <= 20:
        reason.append(f"‡∏´‡∏•‡∏±‡∏á‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏ä‡πà‡∏ß‡∏á‡∏î‡∏µ (‡πÄ‡∏ö‡∏µ‡πà‡∏¢‡∏á‡∏à‡∏≤‡∏Å‡πÅ‡∏ô‡∏ß‡∏ï‡∏£‡∏á ~ {trunk_flex:.1f}¬∞)")
        trunk_score = 2
    elif trunk_flex <= 45:
        reason.append(f"‡∏´‡∏•‡∏±‡∏á‡πÄ‡∏£‡∏¥‡πà‡∏°‡πÄ‡∏≠‡∏ô/‡∏á‡∏≠‡∏°‡∏≤‡∏Å (~ {trunk_flex:.1f}¬∞)")
        trunk_score = 1
    else:
        reason.append(f"‡∏´‡∏•‡∏±‡∏á‡∏á‡∏≠‡∏°‡∏≤‡∏Å‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ (~ {trunk_flex:.1f}¬∞)")
        trunk_score = 0

    # ‡πÄ‡∏Ç‡πà‡∏≤
    if 80 <= knee_angle <= 120:
        reason.append(f"‡∏°‡∏∏‡∏°‡πÄ‡∏Ç‡πà‡∏≤‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏ä‡πà‡∏ß‡∏á‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏° (~ {knee_angle:.1f}¬∞)")
        knee_score = 2
    else:
        reason.append(f"‡∏°‡∏∏‡∏°‡πÄ‡∏Ç‡πà‡∏≤‡∏≠‡∏≤‡∏à‡πÑ‡∏°‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏° (~ {knee_angle:.1f}¬∞)")
        knee_score = 1

    total = neck_score + trunk_score + knee_score

    if total >= 5:
        status = "‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πà‡∏á‡∏î‡∏µ‡∏ï‡∏≤‡∏°‡∏´‡∏•‡∏±‡∏Å‡∏Å‡∏≤‡∏£‡∏¢‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå"
        level = "good"
    elif total >= 3:
        status = "‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πà‡∏á‡∏û‡∏≠‡πÉ‡∏ä‡πâ ‡πÅ‡∏ï‡πà‡∏Ñ‡∏ß‡∏£‡∏õ‡∏£‡∏±‡∏ö‡∏ö‡∏≤‡∏á‡∏à‡∏∏‡∏î"
        level = "caution"
    else:
        status = "‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πà‡∏á‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡∏ï‡πà‡∏≠‡∏Å‡∏≤‡∏£‡∏õ‡∏ß‡∏î‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏¢/‡∏ö‡∏≤‡∏î‡πÄ‡∏à‡πá‡∏ö"
        level = "poor"

    return status, level, reason

# ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏î‡πâ‡∏ß‡∏¢ MediaPipe (fallback)
def analyze_posture_mediapipe_full(img_bgr):
    img_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)
    results = pose.process(img_rgb)

    if not results.pose_landmarks:
        out = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)
        return out, None, None, None, None, "unknown", ["‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÇ‡∏Ñ‡∏£‡∏á‡∏£‡πà‡∏≤‡∏á‡∏ö‡∏∏‡∏Ñ‡∏Ñ‡∏•‡πÉ‡∏ô‡∏†‡∏≤‡∏û"]

    landmarks = results.pose_landmarks.landmark
    side, pts = choose_side_landmarks(landmarks)
    ear = pts["ear"]
    shoulder = pts["shoulder"]
    hip = pts["hip"]
    knee = pts["knee"]
    ankle = pts["ankle"]

    neck_angle = calculate_angle(ear, shoulder, hip)
    trunk_angle = calculate_angle(shoulder, hip, knee)
    knee_angle = calculate_angle(hip, knee, ankle)

    neck_flex = flex_from_straight(neck_angle)
    trunk_flex = flex_from_straight(trunk_angle)

    status, level, reason = classify_ergonomic(neck_flex, trunk_flex, knee_angle)

    annotated = img_bgr.copy()
    mp_drawing.draw_landmarks(
        annotated,
        results.pose_landmarks,
        mp_pose.POSE_CONNECTIONS,
        mp_drawing.DrawingSpec(color=(0, 255, 255), thickness=2, circle_radius=2),
        mp_drawing.DrawingSpec(color=(0, 255, 0), thickness=2)
    )

    out_rgb = cv2.cvtColor(annotated, cv2.COLOR_BGR2RGB)
    return out_rgb, side, neck_flex, trunk_flex, knee_angle, level, reason

# ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏î‡πâ‡∏ß‡∏¢ YOLO (+ fallback)
def analyze_posture_yolo_ergonomic(img_bgr, yolo_conf=0.3):
    h, w, _ = img_bgr.shape
    results = yolo_model(img_bgr, conf=yolo_conf, verbose=False)

    # ‡∏ñ‡πâ‡∏≤ YOLO ‡πÑ‡∏°‡πà‡πÄ‡∏à‡∏≠‡πÄ‡∏•‡∏¢ ‚Üí ‡πÉ‡∏ä‡πâ MediaPipe ‡∏ó‡∏±‡πâ‡∏á‡∏†‡∏≤‡∏û
    if len(results) == 0 or len(results[0].boxes) == 0:
        return analyze_posture_mediapipe_full(img_bgr)

    r = results[0]
    boxes = r.boxes

    # box area
    areas = []
    for box in boxes:
        x1, y1, x2, y2 = box.xyxy[0].tolist()
        areas.append((x2 - x1) * (y2 - y1))
    idx = int(np.argmax(areas))
    box = boxes[idx]

    x1, y1, x2, y2 = box.xyxy[0].tolist()
    x1 = max(0, int(x1))
    y1 = max(0, int(y1))
    x2 = min(h, int(x2))
    y2 = min(w, int(y2))

    cls_id = int(box.cls[0])
    conf = float(box.conf[0])
    cls_name = yolo_model.names.get(cls_id, str(cls_id))

    roi_bgr = img_bgr[y1:y2, x1:x2].copy()
    if roi_bgr.size == 0:
        return analyze_posture_mediapipe_full(img_bgr)

    roi_rgb = cv2.cvtColor(roi_bgr, cv2.COLOR_BGR2RGB)
    pose_results = pose.process(roi_rgb)

    if not pose_results.pose_landmarks:
        return analyze_posture_mediapipe_full(img_bgr)

    landmarks = pose_results.pose_landmarks.landmark
    side, pts = choose_side_landmarks(landmarks)
    ear = pts["ear"]
    shoulder = pts["shoulder"]
    hip = pts["hip"]
    knee = pts["knee"]
    ankle = pts["ankle"]

    neck_angle = calculate_angle(ear, shoulder, hip)
    trunk_angle = calculate_angle(shoulder, hip, knee)
    knee_angle = calculate_angle(hip, knee, ankle)

    neck_flex = flex_from_straight(neck_angle)
    trunk_flex = flex_from_straight(trunk_angle)

    status, level, reason = classify_ergonomic(neck_flex, trunk_flex, knee_angle)

    annotated_roi = roi_bgr.copy()
    mp_drawing.draw_landmarks(
        annotated_roi,
        pose_results.pose_landmarks,
        mp_pose.POSE_CONNECTIONS,
        mp_drawing.DrawingSpec(color=(0, 255, 255), thickness=2, circle_radius=2),
        mp_drawing.DrawingSpec(color=(0, 255, 0), thickness=2)
    )

    annotated_full = img_bgr.copy()
    annotated_full[y1:y2, x1:x2] = annotated_roi

    color_box = (0, 255, 0) if level == "good" else ((0, 255, 255) if level == "caution" else (0, 0, 255))
    cv2.rectangle(annotated_full, (x1, y1), (x2, y2), color_box, 2)
    cv2.putText(
        annotated_full,
        f"{cls_name} {conf:.2f}",
        (x1, max(0, y1 - 10)),
        cv2.FONT_HERSHEY_SIMPLEX,
        0.6,
        color_box,
        2
    )

    out_rgb = cv2.cvtColor(annotated_full, cv2.COLOR_BGR2RGB)
    return out_rgb, side, neck_flex, trunk_flex, knee_angle, level, reason


# UI ‡∏´‡∏•‡∏±‡∏Å
st.divider()
mode = st.radio(
    "‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÅ‡∏´‡∏•‡πà‡∏á‡∏†‡∏≤‡∏û",
    ["‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡∏£‡∏π‡∏õ", "‡∏ñ‡πà‡∏≤‡∏¢‡∏à‡∏≤‡∏Å‡∏Å‡∏•‡πâ‡∏≠‡∏á", "Livecam"],
    horizontal=True
)

yolo_conf = st.slider(
    "confidence",
    0.1, 0.9, 0.3, 0.05,
    help="‡πÉ‡∏ä‡πâ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏Ñ‡∏ß‡∏≤‡∏°‡∏°‡∏±‡πà‡∏ô‡πÉ‡∏à‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡πà‡∏≥‡∏Ç‡∏≠‡∏á YOLO ‡∏Å‡πà‡∏≠‡∏ô‡∏ô‡∏±‡∏ö‡∏ß‡πà‡∏≤‡πÄ‡∏à‡∏≠‡∏Ñ‡∏ô"
)

# ‡πÇ‡∏´‡∏°‡∏î 1‚Äì2: ‡∏†‡∏≤‡∏û‡∏ô‡∏¥‡πà‡∏á (upload/snapshot)
if mode in ["‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡∏£‡∏π‡∏õ", "‡∏ñ‡πà‡∏≤‡∏¢‡∏à‡∏≤‡∏Å‡∏Å‡∏•‡πâ‡∏≠‡∏á"]:
    img_bgr = None

    if mode == "‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡∏£‡∏π‡∏õ":
        file = st.file_uploader("‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡∏£‡∏π‡∏õ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πà‡∏á (‡∏î‡πâ‡∏≤‡∏ô‡∏Ç‡πâ‡∏≤‡∏á‡∏à‡∏∞‡πÅ‡∏°‡πà‡∏ô‡∏Å‡∏ß‡πà‡∏≤)", type=["jpg", "jpeg", "png"])
        if file is not None:
            pil_img = Image.open(file).convert("RGB")
            img_rgb = np.array(pil_img)
            img_bgr = cv2.cvtColor(img_rgb, cv2.COLOR_RGB2BGR)
            st.image(img_rgb, caption="‡∏†‡∏≤‡∏û‡∏ï‡πâ‡∏ô‡∏â‡∏ö‡∏±‡∏ö", use_container_width=True)

    elif mode == "‡∏ñ‡πà‡∏≤‡∏¢‡∏à‡∏≤‡∏Å‡∏Å‡∏•‡πâ‡∏≠‡∏á":
        picture = st.camera_input("‡∏ñ‡πà‡∏≤‡∏¢‡∏†‡∏≤‡∏û‡∏à‡∏≤‡∏Å‡∏Å‡∏•‡πâ‡∏≠‡∏á")
        if picture is not None:
            pil_img = Image.open(picture).convert("RGB")
            img_rgb = np.array(pil_img)
            img_bgr = cv2.cvtColor(img_rgb, cv2.COLOR_RGB2BGR)
            st.image(img_rgb, caption="‡∏†‡∏≤‡∏û‡∏ó‡∏µ‡πà‡∏ñ‡πà‡∏≤‡∏¢", use_container_width=True)

    analyze_btn = st.button("‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå")

    if analyze_btn:
        if img_bgr is None:
            st.warning("‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏´‡∏£‡∏∑‡∏≠‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏†‡∏≤‡∏û‡∏Å‡πà‡∏≠‡∏ô")
        else:
            result_img, side, neck_flex, trunk_flex, knee_angle, level, reason = \
                analyze_posture_yolo_ergonomic(img_bgr, yolo_conf=yolo_conf)

            st.subheader("‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå")

            # layout: ‡∏ã‡πâ‡∏≤‡∏¢‡∏†‡∏≤‡∏û / ‡∏Ç‡∏ß‡∏≤‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
            col_img, col_info = st.columns([2, 1])

            with col_img:
                st.image(result_img, use_container_width=True)

            with col_info:
                st.markdown("**‡∏Ñ‡πà‡∏≤‡∏°‡∏∏‡∏°‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç**")
                st.write(f"- ‡∏î‡πâ‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå: `{side}`")
                st.write(f"- Neck flex (‡πÄ‡∏ö‡∏µ‡πà‡∏¢‡∏á‡∏à‡∏≤‡∏Å‡πÅ‡∏ô‡∏ß‡∏ï‡∏£‡∏á): " +
                         (f"{neck_flex:.1f}¬∞" if neck_flex is not None else "‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡πÑ‡∏î‡πâ"))
                st.write(f"- Trunk flex (‡πÄ‡∏ö‡∏µ‡πà‡∏¢‡∏á‡∏à‡∏≤‡∏Å‡πÅ‡∏ô‡∏ß‡∏ï‡∏£‡∏á): " +
                         (f"{trunk_flex:.1f}¬∞" if trunk_flex is not None else "‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡πÑ‡∏î‡πâ"))
                st.write(f"- Knee angle (‡∏°‡∏∏‡∏°‡πÄ‡∏Ç‡πà‡∏≤): " +
                         (f"{knee_angle:.1f}¬∞" if knee_angle is not None else "‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡πÑ‡∏î‡πâ"))

                st.markdown("---")
                st.markdown("**‡∏™‡∏£‡∏∏‡∏õ‡∏ï‡∏≤‡∏°‡∏´‡∏•‡∏±‡∏Å‡∏Å‡∏≤‡∏£‡∏¢‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå**")
                if level == "good":
                    st.success("‚úÖ ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πà‡∏á‡∏î‡∏µ‡∏ï‡∏≤‡∏°‡∏´‡∏•‡∏±‡∏Å‡∏Å‡∏≤‡∏£‡∏¢‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå")
                elif level == "caution":
                    st.warning("‚ö†Ô∏è ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πà‡∏á‡∏û‡∏≠‡πÉ‡∏ä‡πâ ‡πÅ‡∏ï‡πà‡∏Ñ‡∏ß‡∏£‡∏õ‡∏£‡∏±‡∏ö‡∏ö‡∏≤‡∏á‡∏à‡∏∏‡∏î")
                elif level == "poor":
                    st.error("‚ùå ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πà‡∏á‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡∏ï‡πà‡∏≠‡∏Å‡∏≤‡∏£‡∏õ‡∏ß‡∏î‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏¢/‡∏ö‡∏≤‡∏î‡πÄ‡∏à‡πá‡∏ö")
                else:
                    st.info("‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡πÑ‡∏î‡πâ‡πÅ‡∏ô‡πà‡∏ä‡∏±‡∏î‡∏à‡∏≤‡∏Å‡∏†‡∏≤‡∏û‡∏ô‡∏µ‡πâ")

                if reason:
                    st.markdown("**‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°**")
                    for r in reason:
                        st.write("- " + r)

# ‡πÇ‡∏´‡∏°‡∏î 3: Livecam
elif mode == "Livecam":
    start_live = st.button("‚ñ∂ ‡πÄ‡∏£‡∏¥‡πà‡∏° Livecam")

    if start_live:
        cap = cv2.VideoCapture(0)
        if not cap.isOpened():
            st.error("‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏õ‡∏¥‡∏î‡∏Å‡∏•‡πâ‡∏≠‡∏á‡πÑ‡∏î‡πâ (cv2.VideoCapture(0) ‡∏•‡πâ‡∏°‡πÄ‡∏´‡∏•‡∏ß)")
        else:
            # ‡∏ó‡∏≥ layout ‡∏ã‡πâ‡∏≤‡∏¢/‡∏Ç‡∏ß‡∏≤ ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö live ‡∏î‡πâ‡∏ß‡∏¢
            col_img, col_info = st.columns([2, 1])
            frame_placeholder = col_img.empty()
            info_placeholder = col_info.empty()

            # ‡∏£‡∏±‡∏ô‡∏õ‡∏£‡∏∞‡∏°‡∏≤‡∏ì 300 ‡πÄ‡∏ü‡∏£‡∏°
            for _ in range(300):
                ret, frame = cap.read()
                if not ret:
                    st.warning("‡∏≠‡πà‡∏≤‡∏ô‡πÄ‡∏ü‡∏£‡∏°‡∏à‡∏≤‡∏Å‡∏Å‡∏•‡πâ‡∏≠‡∏á‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ")
                    break

                result_img, side, neck_flex, trunk_flex, knee_angle, level, reason = \
                    analyze_posture_yolo_ergonomic(frame, yolo_conf=yolo_conf)

                frame_placeholder.image(result_img, use_container_width=True)

                with info_placeholder.container():
                    st.markdown("**‡∏Ñ‡πà‡∏≤‡∏°‡∏∏‡∏° (‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡∏à‡∏≤‡∏Å‡∏Å‡∏•‡πâ‡∏≠‡∏á‡∏™‡∏î)**")
                    st.write(f"- ‡∏î‡πâ‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå: `{side}`")
                    st.write(f"- Neck flex: " +
                             (f"{neck_flex:.1f}¬∞" if neck_flex is not None else "N/A"))
                    st.write(f"- Trunk flex: " +
                             (f"{trunk_flex:.1f}¬∞" if trunk_flex is not None else "N/A"))
                    st.write(f"- Knee angle: " +
                             (f"{knee_angle:.1f}¬∞" if knee_angle is not None else "N/A"))

                    st.markdown("---")
                    if level == "good":
                        st.success("‚úÖ ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πà‡∏á‡∏î‡∏µ‡∏ï‡∏≤‡∏°‡∏´‡∏•‡∏±‡∏Å‡∏Å‡∏≤‡∏£‡∏¢‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå")
                    elif level == "caution":
                        st.warning("‚ö†Ô∏è ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πà‡∏á‡∏û‡∏≠‡πÉ‡∏ä‡πâ ‡πÅ‡∏ï‡πà‡∏Ñ‡∏ß‡∏£‡∏õ‡∏£‡∏±‡∏ö‡∏ö‡∏≤‡∏á‡∏à‡∏∏‡∏î")
                    elif level == "poor":
                        st.error("‚ùå ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πà‡∏á‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡∏ï‡πà‡∏≠‡∏Å‡∏≤‡∏£‡∏õ‡∏ß‡∏î‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏¢/‡∏ö‡∏≤‡∏î‡πÄ‡∏à‡πá‡∏ö")
                    else:
                        st.info("‡∏¢‡∏±‡∏á‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡πÑ‡∏î‡πâ‡πÑ‡∏°‡πà‡∏ä‡∏±‡∏î‡∏à‡∏≤‡∏Å‡πÄ‡∏ü‡∏£‡∏°‡∏ô‡∏µ‡πâ")

                time.sleep(0.05)

            cap.release()
